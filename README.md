# ğŸ§  Next Word Prediction Using LSTM-RNN-DL-Project
![App](https://github.com/user-attachments/assets/7077a4f0-c6d2-443d-bafc-0c8afb7c8be6)
![Next Word Prediction Using LSTM And GRU](https://github.com/user-attachments/assets/2701a0a5-fba9-4f71-b963-16878f2f1d14)

---

# ğŸ§  Next Word Prediction Using LSTM & Early Stopping DL project

## ğŸš€ Project Overview  
âœ¨ Today, I built an exciting project called **Next-Word-Prediction-Using-LSTM-&-Early-Stopping**! This **Deep Learning NLP** project uses **Python** and its libraries to analyze and process text, perform **EDA**, apply **Feature Engineering**, and train advanced machine learning and deep learning models.  

ğŸ“œ The project focuses on predicting the next word in a given sequence of words using **Long Short-Term Memory (LSTM)** networks.  
The dataset for training is **Shakespeareâ€™s "Hamlet"**, chosen for its complexity and richness. Additionally, weâ€™ve built a **web application** using **Streamlit**, where users can input a sequence and receive the predicted next word.  

---

## ğŸ” Highlights of the Project  

### ğŸ¯ **Key Goals**  
- **ğŸ“Š Text Analysis**: Gain insights into word patterns and relationships in the dataset.  
- **ğŸ› ï¸ Feature Engineering**: Prepare and preprocess text for model training.  
- **ğŸ§  LSTM Network**: Train a robust model for accurate predictions.  
- **ğŸŒ Web App**: Provide an intuitive interface for real-time next-word prediction.  

---

## ğŸ“Œ Features  

### ğŸ“Š **Exploratory Data Analysis (EDA)**  
- ğŸ” Analyzed the text to understand sequence lengths, unique words, and distributions.  
- ğŸ–‹ï¸ Visualized word frequencies and explored rare terms.  

### ğŸ› ï¸ **Feature Engineering**  
- âœ‚ï¸ Cleaned and preprocessed text by:  
  - Removing punctuation and unnecessary spaces.  
  - Converting text to lowercase for uniformity.  
- ğŸ”¤ **Tokenized sentences** and created sequences for model training.  
- ğŸ”¢ Generated numerical representations of text using word embeddings.  

### ğŸ§  **Model Building**  
- ğŸ”¥ **LSTM-based Deep Learning Model**:  
  - Designed a sequence-to-sequence prediction network.  
  - Integrated **Early Stopping** to optimize training.  
  - Tuned hyperparameters for better performance.  
- ğŸ¯ Achieved high accuracy in generating contextually accurate next words.  

### ğŸŒ **Streamlit Web Application**  
- ğŸ—ï¸ Built an interactive web app where users can input a word sequence and get the next predicted word.  
- ğŸ“‹ Displayed the prediction and model confidence score in real-time.  

---

## ğŸ› ï¸ Tools & Libraries Used  

| ğŸ› ï¸ **Tool/Library**  | ğŸ” **Purpose**                             |  
|-----------------------|-------------------------------------------|  
| ğŸ”¥ TensorFlow 2.15.0  | Deep Learning framework                   |  
| ğŸ“¦ Pandas, NumPy      | Data manipulation and numerical operations|  
| ğŸ¤– Scikit-learn       | Preprocessing and evaluation              |  
| ğŸ›ï¸ Scikeras           | Keras-compatible Scikit-learn integration|  
| ğŸ“Š Matplotlib         | Data visualization                       |  
| ğŸ“‚ TensorBoard        | Model monitoring and analysis             |  
| ğŸŒ Streamlit          | Web app development                      |  

---

## ğŸ›¤ï¸ Workflow  

1. **ğŸ“‚ Data Preparation**: Load Shakespeare's *Hamlet* text as the dataset.  
2. **ğŸ§¹ Data Cleaning**: Standardize, tokenize, and preprocess the text data.  
3. **ğŸ“Š EDA**:  
   - Visualize sequence lengths and word frequencies.  
   - Explore vocabulary size and trends.  
4. **ğŸ› ï¸ Feature Engineering**:  
   - Convert text into tokenized sequences.  
   - Pad sequences to ensure uniformity for training.  
5. **ğŸ¤– Model Building**:  
   - Train an LSTM-based deep learning model.  
   - Implement **Early Stopping** for efficient training.  
6. **ğŸŒ Web App**: Build a Streamlit app for real-time predictions.  
7. **ğŸ¯ Prediction**: Generate contextually accurate next words.  

---

## ğŸ“‚ How to Run  

1. **ğŸ“¥ Clone the Repository**:  
   ```bash  
   git clone https://github.com/abhishekkumar62000/Next-Word-Prediction-Using-LSTM-RNN-Project 
   ```  
2. **ğŸ“ Navigate to the Directory**:  
   ```bash  
   cd next-word-prediction  
   ```  
3. **ğŸ“¦ Install Dependencies**:  
   ```bash  
   pip install -r requirements.txt  
   ```  
4. **ğŸƒ Run the Web App**:  
   ```bash  
   streamlit run app.py  
   ```  

---

## ğŸ‰ Results  

The LSTM model achieved:  
- ğŸ† High training and validation accuracy using Early Stopping.  
- ğŸ’¡ Real-time next-word predictions on Shakespearean text sequences.  

---

## ğŸ¤ Contributions  

âœ¨ Contributions are welcome! Feel free to:  
- Report issues  
- Suggest new features or enhancements  
- Submit pull requests  

---

## ğŸ“œ License  

This project is licensed under the **MIT License**.  

---  
